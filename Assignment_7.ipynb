{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a51295madhuri/HPC-LAB/blob/main/Assignment_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector Addition (Scalar vs SIMD-like)**"
      ],
      "metadata": {
        "id": "JE-aOxnXGzl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz38WBVjDMu1",
        "outputId": "eaf51c34-4a45-4c51-945d-41d28dc6a5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal loop time: 7.10044527053833\n",
            "Vectorized time: 0.04449152946472168\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "\n",
        "A = np.arange(N, dtype=np.float64)\n",
        "B = np.arange(N, dtype=np.float64)\n",
        "\n",
        "# Scalar loop\n",
        "C = np.zeros(N)\n",
        "start = time.time()\n",
        "for i in range(N):\n",
        "    C[i] = A[i] + B[i]\n",
        "end = time.time()\n",
        "print(\"Normal loop time:\", end - start)\n",
        "\n",
        "# Vectorized (SIMD-like)\n",
        "start = time.time()\n",
        "C = A + B\n",
        "end = time.time()\n",
        "print(\"Vectorized time:\", end - start)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION\n",
        "\n",
        "The first part uses a normal Python for loop to add arrays element-by-element, which is slow because Python executes each iteration sequentially.\n",
        "\n",
        "The second part uses C = A + B, a NumPy vectorized operation that performs all additions at once using optimized low-level (SIMD-like) instructions.\n",
        "\n",
        "Therefore, the vectorized version runs much faster and demonstrates the performance benefit of data-level parallelism."
      ],
      "metadata": {
        "id": "18GP5dVSZkvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reduction (Sum)**\n"
      ],
      "metadata": {
        "id": "wGo1GUDiG43N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "A = np.ones(N, dtype=np.float64)\n",
        "\n",
        "# Normal loop\n",
        "start = time.time()\n",
        "s = 0.0\n",
        "for i in range(N):\n",
        "    s += A[i]\n",
        "end = time.time()\n",
        "print(\"Normal sum:\", s, \"Time:\", end - start)\n",
        "\n",
        "# Vectorized reduction\n",
        "start = time.time()\n",
        "s = np.sum(A)\n",
        "end = time.time()\n",
        "print(\"Vectorized sum:\", s, \"Time:\", end - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTfqsXarDh8r",
        "outputId": "73dd1dee-f670-4fa3-a0ac-6b58ceb9a47d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal sum: 10000000.0 Time: 2.6535258293151855\n",
            "Vectorized sum: 10000000.0 Time: 0.007744550704956055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANATION\n",
        "\n",
        "1. This program creates a large array of 10 million elements filled with ones using NumPy.\n",
        "2. The first method calculates the sum using a normal Python loop, which is slow because each addition is executed sequentially.\n",
        "3. The second method uses np.sum(A), a vectorized reduction that performs the operation internally using optimized SIMD-like instructions, making it much faster."
      ],
      "metadata": {
        "id": "TGcNfSSMaLup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memory Alignment Effect**"
      ],
      "metadata": {
        "id": "u7J3IzA-G737"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "\n",
        "unaligned = np.arange(N + 1, dtype=np.float64)[1:]\n",
        "aligned = np.arange(N, dtype=np.float64)\n",
        "\n",
        "start = time.time()\n",
        "np.sum(unaligned)\n",
        "print(\"Unaligned time:\", time.time() - start)\n",
        "\n",
        "start = time.time()\n",
        "np.sum(aligned)\n",
        "print(\"Aligned time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkobRbKXDwL8",
        "outputId": "1b8b49d5-c795-41c1-959b-e1d44bebd22b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unaligned time: 0.008980274200439453\n",
            "Aligned time: 0.007965087890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "\n",
        "The program creates two arrays – one properly memory aligned and one slightly shifted (unaligned) by slicing.\n",
        "\n",
        "It measures the time taken to compute the sum of both arrays using np.sum().\n",
        "\n",
        "The aligned array executes faster because SIMD operations work more efficiently on properly aligned memory."
      ],
      "metadata": {
        "id": "SMLs-xqsaeQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parallel + SIMD (Implicit)**"
      ],
      "metadata": {
        "id": "wIBWs1XYG_Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "A = np.arange(N, dtype=np.float64)\n",
        "\n",
        "start = time.time()\n",
        "B = A * 2.0\n",
        "print(\"Vectorized (SIMD + multithreaded) time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ruYbIHD3En",
        "outputId": "d31fc9d8-a192-4d14-aa19-414c46093d11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorized (SIMD + multithreaded) time: 0.026386737823486328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "\n",
        "The program creates a large NumPy array of 10 million floating-point numbers.\n",
        "\n",
        "The operation B = A * 2.0 performs element-wise multiplication using NumPy’s vectorized implementation.\n",
        "\n",
        "This computation runs very fast because NumPy internally uses SIMD instructions and multithreading for parallel execution."
      ],
      "metadata": {
        "id": "XR1KV_bKau3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Branch Divergence**"
      ],
      "metadata": {
        "id": "xdOV9SnmHDXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "A = np.random.rand(N) * 100\n",
        "B = np.zeros(N)\n",
        "\n",
        "start = time.time()\n",
        "for i in range(N):\n",
        "    if A[i] > 50:\n",
        "        B[i] = A[i] * 2\n",
        "    else:\n",
        "        B[i] = A[i] / 2\n",
        "print(\"Branch loop time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgqvZ5A8D_4u",
        "outputId": "d73c5ed4-6ca9-4e35-88e2-3b798c0377f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch loop time: 6.728229284286499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The program creates a large array with random values and processes each element using a normal Python loop with an if-else condition.\n",
        "\n",
        "Because every iteration contains a branch decision, the CPU cannot effectively use SIMD vectorization.\n",
        "\n",
        "This branch-heavy loop runs slowly compared to a vectorized implementation that avoids conditional branching."
      ],
      "metadata": {
        "id": "URA2H4iKa8uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "B = np.where(A > 50, A * 2, A / 2)\n",
        "print(\"Vectorized conditional time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joYjDZ7pEFLC",
        "outputId": "6eede867-0eb0-48aa-b2b1-f63ab9fdde42"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorized conditional time: 0.17036724090576172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code replaces the slow loop with a fully vectorized operation using np.where.\n",
        "\n",
        "The condition and computations are applied to the entire array at once instead of element-by-element.\n",
        "\n",
        "As a result, it runs much faster because NumPy performs the operation using optimized SIMD-style execution without branching."
      ],
      "metadata": {
        "id": "UsF7npRAbHAY"
      }
    }
  ]
}